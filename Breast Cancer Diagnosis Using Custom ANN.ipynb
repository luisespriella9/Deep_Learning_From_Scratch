{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activations:\n",
    "    @staticmethod\n",
    "    def step(x):\n",
    "        if x < 0:\n",
    "            return 0\n",
    "        return 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1+np.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh(x):\n",
    "        return (2 / (1+np.exp(-2*x))) - 1\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x):\n",
    "        print(\"x relu: \", x)\n",
    "        return np.max(0, x)\n",
    "\n",
    "    @staticmethod\n",
    "    def leaky_relu(x):\n",
    "        if x>=0:\n",
    "            return x\n",
    "        return 0.3*x\n",
    "    \n",
    "    @staticmethod\n",
    "    def elu(x, alpha=1):\n",
    "        if x>=0:\n",
    "            return x\n",
    "        return alpha*(np.exp(x)-1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def binary(x):\n",
    "        if x>= 0.5:\n",
    "            return 1\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Function derivates to compute gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationDerivatives:\n",
    "    @staticmethod\n",
    "    def step_deriv(x):\n",
    "        return 0\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_deriv(x):\n",
    "        sigmoid = Activations.sigmoid(x)\n",
    "        return sigmoid*(1-sigmoid)\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh_deriv(x):\n",
    "        return 1 - np.sqrt(Activations.tanh(x))\n",
    "\n",
    "    @staticmethod\n",
    "    def relu_deriv(x):\n",
    "        if x<0:\n",
    "            return 0\n",
    "        return 1\n",
    "\n",
    "    @staticmethod\n",
    "    def leaky_relu_deriv(x):\n",
    "        if x>=0:\n",
    "            return 1\n",
    "        return 0.3\n",
    "\n",
    "    @staticmethod\n",
    "    def elu_deriv(x, alpha=1):\n",
    "        if x<0:\n",
    "            return Activations.elu(x)+alpha\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    @staticmethod\n",
    "    # Regression Mean Squared Error\n",
    "    def mse(targets, predictions):\n",
    "        differences_squared = (predictions-targets)**2\n",
    "        return np.sum(differences_squared)\n",
    "    \n",
    "    @staticmethod\n",
    "    # Binary Cross Entropy\n",
    "    def binary_cross_entropy(y_target, prob):\n",
    "        return -(y_target*np.log(prob) + (1-y_target)*np.log(1-prob))\n",
    "    \n",
    "    @staticmethod\n",
    "    def mse_prime(y_target, prediction):\n",
    "        return prediction-y_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense():\n",
    "    def __init__(self, units, activation, input_dim = None):\n",
    "        available_activations = ['step', 'sigmoid', 'tanh', 'relu', 'leaky_relu', 'elu']\n",
    "        activations = [Activations.step, Activations.sigmoid, Activations.tanh, Activations.relu, Activations.leaky_relu, Activations.elu]\n",
    "        activation_derivs = [ActivationDerivatives.step_deriv, ActivationDerivatives.sigmoid_deriv, ActivationDerivatives.tanh_deriv, ActivationDerivatives.relu_deriv, ActivationDerivatives.leaky_relu_deriv, ActivationDerivatives.elu_deriv]\n",
    "        index = available_activations.index(activation)\n",
    "        if not index:\n",
    "            print(\"Error. Activation not found, list of available activations are: \", available_activations)\n",
    "            return\n",
    "        self.units = units\n",
    "        self.input_dim = input_dim\n",
    "        self.activation = activations[index]\n",
    "        self.activation_deriv = activation_derivs[index]\n",
    "        \n",
    "        self.input = []\n",
    "        self.activations = []\n",
    "        \n",
    "    def compile_layer(self, input_dim=None):\n",
    "        if (self.input_dim != None):\n",
    "            input_dim = self.input_dim\n",
    "        self.weights = np.random.rand(input_dim, self.units) # initialize weights\n",
    "        self.b = np.random.rand()\n",
    "        return self.units\n",
    "        \n",
    "    def propagate(self, x):\n",
    "        z = np.dot(x, self.weights) + self.b\n",
    "        self.input = z\n",
    "        self.activations = self.activation(z)\n",
    "        return self.activations\n",
    "    \n",
    "    def backpropagate(self, local_gradient, learning_rate):\n",
    "        errors = np.multiply(local_gradient, self.activations)\n",
    "        layer_gradient = np.array([self.activation_deriv(a) for a in self.activations])*errors\n",
    "        for gradient in layer_gradient:\n",
    "            self.b -= gradient\n",
    "        for index in range(self.weights.shape[0]):\n",
    "            self.weights[index] -= (learning_rate * layer_gradient[index] * self.input[index])\n",
    "        return layer_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.layers = []\n",
    "        self.loss = Loss.mse_prime\n",
    "        self.learning_rate = lr\n",
    "        \n",
    "    def compile_layers(self):\n",
    "        input_dim = self.layers[0].compile_layer()\n",
    "        for i in range(1, len(self.layers)):\n",
    "            input_dim = self.layers[i].compile_layer(input_dim)\n",
    "    \n",
    "    def fit(self, x, y, epochs=20, batch_size=4):\n",
    "        dataset_size=x.shape[0]\n",
    "        if batch_size>dataset_size:\n",
    "            print(\"Error. Batch size cannot be greater than dataset size\")\n",
    "            return\n",
    "        for epoch in range(epochs):\n",
    "            # assume batch size is 1 for now\n",
    "            batch_start = 0\n",
    "            batch_end = batch_size\n",
    "            while batch_end < dataset_size:\n",
    "                if (batch_end > dataset_size):\n",
    "                    batch_end = dataset_size\n",
    "                x_sample = x[batch_start:batch_end]\n",
    "                y_batch = y[batch_start:batch_end]\n",
    "                predictions = self.propagate(x_sample)\n",
    "                self.backpropagate(y_batch, predictions)\n",
    "                batch_start+=batch_size\n",
    "                batch_end+=batch_size\n",
    "    \n",
    "    def predict(self, x):\n",
    "        predictions = []\n",
    "        for x_sample in x:\n",
    "            predictions.append(self.propagate(x_sample))\n",
    "        return predictions\n",
    "    \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def propagate(self, x_batch):\n",
    "        for i in range(len(self.layers)):\n",
    "            x_batch = np.array(self.layers[i].propagate(x_batch))\n",
    "        prediction = x_batch\n",
    "        return prediction\n",
    "    \n",
    "    def backpropagate(self, y_target, prediction_values):\n",
    "        output_layer = self.layers[-1]\n",
    "        errors = self.loss(y_target, prediction_values)\n",
    "        local_gradient = np.array([output_layer.activation_deriv(a) for a in output_layer.activations])*errors\n",
    "        output_layer.weights -= self.learning_rate*np.dot(output_layer.input.T, local_gradient)\n",
    "        for gradient in local_gradient:\n",
    "            output_layer.b -= gradient\n",
    "        for i in range(len(self.layers)-2, -1, -1):\n",
    "            self.layers[i].backpropagate(local_gradient, self.learning_rate)\n",
    "            \n",
    "    \n",
    "    def summary(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_data = pd.read_csv('Data/breast_cancer_diagnosis_data.csv')\n",
    "breast_cancer_data.drop(['id'], axis=1, inplace=True)\n",
    "breast_cancer_data.dropna(axis='columns', inplace=True)\n",
    "breast_cancer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(breast_cancer_data['diagnosis']) #Malignant or Benign\n",
    "def diagnosis_to_binary(diagnosis):\n",
    "    if diagnosis=='B':\n",
    "        return 0\n",
    "    elif diagnosis=='M':\n",
    "        return 1\n",
    "    \n",
    "breast_cancer_data['diagnosis'] = breast_cancer_data['diagnosis'].apply(diagnosis_to_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_units(arr):\n",
    "    return (arr-np.mean(arr))/np.std(arr)\n",
    "                   \n",
    "def correlation(a, b):\n",
    "    return np.mean(standard_units(a)*standard_units(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlations(df, y_feature):\n",
    "    feature_correlations = {}\n",
    "    y = df[y_feature].values\n",
    "    df_copy = df.drop([y_feature], axis = 1)\n",
    "    print(\"Explore Correlation between features and \" + str(y_feature))\n",
    "    for column in df_copy:\n",
    "        corr = correlation(df[column].values, y)\n",
    "        feature_correlations[column] = corr\n",
    "        print(str(column)+\" Correlation: \" + str(corr))\n",
    "    return feature_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore Correlation between features and diagnosis\n",
      "radius_mean Correlation: 0.7300285113754565\n",
      "texture_mean Correlation: 0.4151852998452045\n",
      "perimeter_mean Correlation: 0.7426355297258332\n",
      "area_mean Correlation: 0.7089838365853901\n",
      "smoothness_mean Correlation: 0.3585599650859321\n",
      "compactness_mean Correlation: 0.5965336775082535\n",
      "concavity_mean Correlation: 0.6963597071719059\n",
      "concave points_mean Correlation: 0.7766138400204355\n",
      "symmetry_mean Correlation: 0.33049855426254715\n",
      "fractal_dimension_mean Correlation: -0.012837602698432387\n",
      "radius_se Correlation: 0.5671338208247177\n",
      "texture_se Correlation: -0.008303332973877421\n",
      "perimeter_se Correlation: 0.5561407034314833\n",
      "area_se Correlation: 0.5482359402780244\n",
      "smoothness_se Correlation: -0.06701601057948733\n",
      "compactness_se Correlation: 0.2929992442488584\n",
      "concavity_se Correlation: 0.25372976598083036\n",
      "concave points_se Correlation: 0.40804233271650475\n",
      "symmetry_se Correlation: -0.006521755870647961\n",
      "fractal_dimension_se Correlation: 0.07797241739025616\n",
      "radius_worst Correlation: 0.7764537785950397\n",
      "texture_worst Correlation: 0.4569028213967983\n",
      "perimeter_worst Correlation: 0.7829141371737595\n",
      "area_worst Correlation: 0.7338250349210511\n",
      "smoothness_worst Correlation: 0.42146486106640274\n",
      "compactness_worst Correlation: 0.590998237841792\n",
      "concavity_worst Correlation: 0.6596102103692332\n",
      "concave points_worst Correlation: 0.7935660171412701\n",
      "symmetry_worst Correlation: 0.41629431104861914\n",
      "fractal_dimension_worst Correlation: 0.3238721887208239\n"
     ]
    }
   ],
   "source": [
    "feature_correlations = correlations(breast_cancer_data, 'diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_correlations(feature_correlations, threshold=0.8):\n",
    "    correlations_chosen = []\n",
    "    for feature in feature_correlations:\n",
    "        if feature_correlations[feature] >= threshold:\n",
    "            correlations_chosen.append(feature)\n",
    "    return correlations_chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose features with correlation higher than 0.75\n",
    "columns_to_keep = pick_correlations(feature_correlations, threshold=0.73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>122.80</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>25.38</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.2654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>132.90</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>24.99</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>130.00</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>23.57</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.2430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>77.58</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>14.91</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>135.10</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>22.54</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  perimeter_mean  concave points_mean  radius_worst  \\\n",
       "0        17.99          122.80              0.14710         25.38   \n",
       "1        20.57          132.90              0.07017         24.99   \n",
       "2        19.69          130.00              0.12790         23.57   \n",
       "3        11.42           77.58              0.10520         14.91   \n",
       "4        20.29          135.10              0.10430         22.54   \n",
       "\n",
       "   perimeter_worst  area_worst  concave points_worst  \n",
       "0           184.60      2019.0                0.2654  \n",
       "1           158.80      1956.0                0.1860  \n",
       "2           152.50      1709.0                0.2430  \n",
       "3            98.87       567.7                0.2575  \n",
       "4           152.20      1575.0                0.1625  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_data_diagnosis = breast_cancer_data[['diagnosis']]\n",
    "breast_cancer_data_features = breast_cancer_data[columns_to_keep]\n",
    "breast_cancer_data_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Tran and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(breast_cancer_data_features, breast_cancer_data_diagnosis, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train samples:  [[ 0.35581988  0.4130312   1.5938771   0.5110286   0.52179366  0.37393498\n",
      "   1.0565228 ]\n",
      " [-0.37326664 -0.39470002 -0.7896234  -0.39223224 -0.473485   -0.4140696\n",
      "  -0.8966741 ]\n",
      " [ 1.4033579   1.3479992   1.0764874   2.0233212   1.8669261   2.1755323\n",
      "   1.4635353 ]\n",
      " [-0.47941723 -0.48331875 -0.6581813  -0.46218845 -0.4379925  -0.48057154\n",
      "  -0.13676336]\n",
      " [-0.48221073 -0.48413163 -0.46704042 -0.585641   -0.5778744  -0.57730156\n",
      "  -0.5846312 ]]\n",
      "x test samples:  [[-0.47941723 -0.45730227 -0.27799425 -0.27495223 -0.34165588 -0.3586225\n",
      "  -0.19534856]\n",
      " [ 1.3279356   1.2707627   0.8033918   1.7599561   1.7416584   1.6936095\n",
      "   0.9979379 ]\n",
      " [ 0.35581988  0.38051045  0.8390016   0.6077329   0.51881117  0.46721038\n",
      "   0.5739667 ]\n",
      " [-0.49897146 -0.44185477 -0.5455915  -0.7049784  -0.5337325  -0.63862157\n",
      "  -0.6239449 ]\n",
      " [-0.73920673 -0.7190931  -0.5992681  -0.83254594 -0.8567432  -0.73880625\n",
      "  -0.69363046]]\n",
      "y train samples:  [[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "y test samples:  [[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# make sure they are in numpy form\n",
    "x_train = np.array(x_train.values, dtype=np.float32)\n",
    "x_test = np.array(x_test.values, dtype=np.float32)\n",
    "y_train = np.array(y_train.values, dtype=np.uint8)\n",
    "y_test = np.array(y_test.values, dtype=np.uint8)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "print(\"x train samples: \", x_train[:5])\n",
    "print(\"x test samples: \", x_test[:5])\n",
    "print(\"y train samples: \", y_train[:5])\n",
    "print(\"y test samples: \", y_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Model(lr=0.008)\n",
    "\n",
    "# add Hidden Layer Layer\n",
    "hl1 = Dense(units=15, activation='sigmoid', input_dim=len(x_train[0]))\n",
    "model.add(hl1)\n",
    "\n",
    "# add Output Layer\n",
    "output_layer = Dense(units=1, activation='sigmoid')\n",
    "model.add(output_layer)\n",
    "\n",
    "model.compile_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.49946934e-01, 3.83083253e-01, 4.96963092e-01, 7.22959043e-01,\n",
       "        7.46097325e-01, 6.46601287e-01, 6.38374311e-02, 9.20810101e-01,\n",
       "        3.71371037e-01, 8.71522182e-01, 7.63219545e-01, 6.86620642e-01,\n",
       "        9.79498953e-01, 6.27032544e-01, 8.72991495e-01],\n",
       "       [3.66896564e-01, 2.96763845e-01, 3.95370555e-01, 7.46813966e-01,\n",
       "        7.46002023e-01, 2.74893541e-01, 4.14087121e-01, 1.59811151e-01,\n",
       "        5.39090465e-01, 3.22391569e-01, 7.54493859e-01, 7.12911118e-01,\n",
       "        2.10304315e-01, 5.29340086e-01, 4.00628274e-01],\n",
       "       [6.87753587e-01, 8.59222141e-01, 5.98151008e-01, 7.60902535e-01,\n",
       "        4.06924324e-02, 1.17767336e-01, 2.61241875e-01, 4.22213486e-01,\n",
       "        1.73697005e-02, 1.86932808e-01, 5.46663644e-02, 2.55909133e-02,\n",
       "        9.46897293e-01, 4.59072435e-01, 8.38981689e-01],\n",
       "       [8.58271933e-04, 4.36504115e-01, 6.28395019e-01, 5.75310573e-01,\n",
       "        8.86187506e-02, 8.41143846e-01, 2.68053036e-01, 5.19463441e-01,\n",
       "        9.93037266e-01, 9.61239163e-01, 5.83865778e-01, 9.94454485e-01,\n",
       "        2.21992172e-01, 6.64260257e-01, 4.18739011e-01],\n",
       "       [5.66594149e-01, 7.36450682e-01, 1.07177779e-02, 7.49797931e-01,\n",
       "        4.18503796e-01, 4.39307566e-01, 7.52634009e-01, 1.87742076e-01,\n",
       "        8.99715754e-01, 5.30264137e-01, 2.35387240e-01, 9.59015519e-01,\n",
       "        3.73734232e-02, 1.69685525e-01, 6.83322363e-01],\n",
       "       [6.96840962e-01, 6.20309326e-02, 4.41135656e-01, 2.58945995e-01,\n",
       "        3.99201986e-01, 2.93776511e-01, 5.99001450e-01, 4.18926854e-01,\n",
       "        8.16563797e-01, 5.57294998e-01, 9.36299515e-01, 1.47448012e-01,\n",
       "        6.46167766e-01, 5.69657815e-02, 7.28578581e-01],\n",
       "       [9.98706722e-01, 1.19466865e-01, 7.65901717e-01, 6.47402939e-01,\n",
       "        9.87721305e-01, 1.63437397e-01, 5.33024863e-01, 5.60128847e-01,\n",
       "        1.77508070e-02, 6.21862313e-02, 8.62149848e-01, 3.82383107e-01,\n",
       "        6.79598748e-01, 1.78251703e-01, 1.81765466e-01]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32228455],\n",
       "       [0.7767414 ],\n",
       "       [0.87020354],\n",
       "       [0.62531461],\n",
       "       [0.8041837 ],\n",
       "       [0.69101008],\n",
       "       [0.94029136],\n",
       "       [0.46389576],\n",
       "       [0.21918817],\n",
       "       [0.28051403],\n",
       "       [0.07688939],\n",
       "       [0.6027361 ],\n",
       "       [0.09972335],\n",
       "       [0.0162104 ],\n",
       "       [0.02695112]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=80, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90535653, 0.53450388, 0.71334309, 0.89823979, 0.88470156,\n",
       "        0.69176437, 0.22789929, 1.05677476, 0.43303345, 0.92951317,\n",
       "        0.88055074, 0.75664973, 1.20691138, 0.68998004, 0.98701275],\n",
       "       [0.34670902, 0.273644  , 0.36895109, 0.74529494, 0.74230182,\n",
       "        0.29739661, 0.39623547, 0.14945696, 0.57720696, 0.35569632,\n",
       "        0.77022465, 0.74637004, 0.18229473, 0.53635963, 0.4133919 ],\n",
       "       [0.7361295 , 0.8787511 , 0.63253811, 0.79342285, 0.06794342,\n",
       "        0.13580304, 0.30108923, 0.44525665, 0.04278897, 0.20877223,\n",
       "        0.08599656, 0.05046241, 0.97363211, 0.47080283, 0.86414089],\n",
       "       [0.08396201, 0.46064684, 0.68515619, 0.59767005, 0.10454228,\n",
       "        0.8218305 , 0.28910279, 0.52752651, 0.97763185, 0.94880955,\n",
       "        0.56693461, 0.97822475, 0.28553502, 0.65497387, 0.41645842],\n",
       "       [0.65751811, 0.78956805, 0.08043323, 0.83151041, 0.47621228,\n",
       "        0.48214731, 0.80734879, 0.24071722, 0.96025007, 0.58516014,\n",
       "        0.30653039, 1.02190544, 0.11422849, 0.21054345, 0.75614796],\n",
       "       [0.73600213, 0.08620413, 0.47231897, 0.30240285, 0.43316027,\n",
       "        0.33009894, 0.63619974, 0.45245326, 0.86638782, 0.6002443 ,\n",
       "        0.98899463, 0.19479702, 0.67375868, 0.08246769, 0.77315126],\n",
       "       [1.03771923, 0.16109014, 0.79435077, 0.72003644, 1.02593464,\n",
       "        0.218908  , 0.55531046, 0.60146893, 0.09161215, 0.13385067,\n",
       "        0.92666278, 0.45853188, 0.72429956, 0.23379912, 0.26897069]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61076125],\n",
       "       [1.0652181 ],\n",
       "       [1.15868024],\n",
       "       [0.91379131],\n",
       "       [1.0926604 ],\n",
       "       [0.97948678],\n",
       "       [1.22876806],\n",
       "       [0.75237246],\n",
       "       [0.50766487],\n",
       "       [0.56899073],\n",
       "       [0.36536609],\n",
       "       [0.8912128 ],\n",
       "       [0.38820006],\n",
       "       [0.3046871 ],\n",
       "       [0.31542782]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Results on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(x_test)\n",
    "test_predictions = np.array([1 if x>0.5 else 0 for x in test_predictions], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[114,   7],\n",
       "       [  1,  66]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9574468085106383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"accuracy: \", accuracy_score(y_test, test_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
